<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>paiutils.audio API documentation</title>
<meta name="description" content="Author: Travis Hammond
Version: 12_21_2020" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>paiutils.audio</code></h1>
</header>
<section id="section-intro">
<p>Author: Travis Hammond
Version: 12_21_2020</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Author: Travis Hammond
Version: 12_21_2020
&#34;&#34;&#34;


import os
import subprocess
import wave
import numpy as np
from matplotlib import pyplot as plt
from scipy.fftpack import dct

try:
    import webrtcvad
except ModuleNotFoundError:
    print(&#39;ModuleError: webrtcvad could not be found. &#39;
          &#39;Therefore, vad_trim_all, vad_trim_sides, &#39;
          &#39;and vad_split cannot be used.&#39;)

USE_PYAUDIO = False
try:
    import pyaudio
    USE_PYAUDIO = True
except ModuleNotFoundError:
    print(&#39;ModuleError: pyaudio could not be found. &#39;
          &#39;Therefore, sox will be used for recording and playing audio.&#39;)

util_dir = os.path.dirname(__file__)

if os.name == &#39;nt&#39;:
    SOX_PATH = os.path.join(util_dir, &#39;sox&#39;, &#39;sox.exe&#39;)
    if not os.path.exists(SOX_PATH):
        print(f&#39;SoX does not exist or is not in the &#39;
              f&#39;location: {SOX_PATH}\nDownload SoX: &#39;
              f&#39;https://sourceforge.net/projects/sox/\n&#39;
              f&#39;Some functionally will be disabled until resolved.&#39;)
else:
    SOX_PATH = None
    if SOX_PATH is None:
        print(&#39;SoX is only configured to work with Windows, &#39;
              &#39;so some functionally will be disabled.&#39;)


CHUNK = 1000


def convert_width_to_atype(width):
    &#34;&#34;&#34;Converts a number of bytes to an audio type.

    Args:
        width: An integer, which is the number of bytes wide
    
    Returns:
        A string, which is the audio type
    &#34;&#34;&#34;
    if width == 1:
        atype = &#39;int8&#39;
    elif width == 2:
        atype = &#39;int16&#39;
    else:
        raise ValueError(&#39;Supported widths are either 1 or 2&#39;)
    return atype


def convert_atype_to_width(atype):
    &#34;&#34;&#34;Converts an audio type to the number of bytes each value takes.

    Args:
        atype: A string, which is an audio type

    Returns:
        An integer, which is the number of bytes wide
    &#34;&#34;&#34;
    if atype == &#39;int8&#39;:
        return 1
    if atype == &#39;int16&#39;:
        return 2
    raise ValueError(&#39;Supported atypes are either int8 or int16&#39;)


def change_rate(audio, rate, new_rate, atype=None):
    &#34;&#34;&#34;Changes the audio&#39;s sample rate.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        new_rate: An integer, which is the rate to change the audio to

    Returns:
        A tuple of the loaded audio, rate, and atype
    &#34;&#34;&#34;
    if rate == new_rate:
        return audio, rate
    temp_filename = os.path.join(
        util_dir, str(np.random.randint(10000, 100000)) + &#39;.wav&#39;
    )
    save(temp_filename, audio, rate, atype=atype)
    try:
        audio, rate, atype = load(temp_filename, new_rate)
    finally:
        os.remove(temp_filename)
    return audio, rate, atype


def load(filename, rate=None, assert_mono=True):
    &#34;&#34;&#34;Changes the audio&#39;s sample rate.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
        rate: An integer, which is the rate at which samples are taken
        assert_mono: A boolean, which determines if an assertion error
                     should be raise if there are more than one channel
                     in the audio or if it should be converted to one
                     channel

    Returns:
        A tuple of the loaded audio, rate, and atype
    &#34;&#34;&#34;
    if filename.split(&#39;.&#39;)[-1] == &#39;wav&#39;:
        file = wave.open(filename, &#39;r&#39;)
        assert file.getnchannels() == 1 or not assert_mono, (
            &#39;Can only load mono-channel files&#39;
        )
    if (filename.split(&#39;.&#39;)[-1] == &#39;wav&#39;
            and file.getnchannels() == 1
            and (rate is None or file.getframerate() == rate)):
        atype = convert_width_to_atype(file.getsampwidth())
        rate = file.getframerate()
        audio = file.readframes(file.getnframes())
        audio = np.frombuffer(audio, dtype=atype) / np.iinfo(atype).max
        file.close()
    else:
        if filename.split(&#39;.&#39;)[-1] == &#39;wav&#39;:
            file.close()
        temp_filename = os.path.join(
            util_dir, str(np.random.randint(10000, 100000))+&#39;.wav&#39;
        )
        if rate is None:
            cmd = [SOX_PATH, filename, &#39;-c 1&#39;, temp_filename]
        else:
            cmd = [SOX_PATH, filename, &#39;-r &#39; + str(rate), &#39;-c 1&#39;,
                   temp_filename]
        subprocess.run(cmd, stdout=subprocess.DEVNULL,
                       stderr=subprocess.DEVNULL)
        try:
            with wave.open(temp_filename, &#39;r&#39;) as file:
                atype = convert_width_to_atype(file.getsampwidth())
                rate = file.getframerate()
                audio = file.readframes(file.getnframes())
                audio = np.frombuffer(audio, dtype=atype) / np.iinfo(atype).max
        finally:
            os.remove(temp_filename)
    return audio, rate, atype


def save(filename, audio, rate, atype=None):
    &#34;&#34;&#34;Saves the audio to a file.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
    &#34;&#34;&#34;
    if atype is None:
        atype = &#39;int16&#39;
    with wave.open(filename, &#39;wb&#39;) as file:
        file.setframerate(rate)
        file.setnchannels(1)
        file.setsampwidth(convert_atype_to_width(atype))
        audio = (audio * np.iinfo(atype).max).astype(atype)
        file.writeframes(audio.tobytes())


def file_record(filename, seconds, rate, atype=None,
                recording_device_name=&#39;Microphone&#39;):
    &#34;&#34;&#34;Records audio from the recording device to a file.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
        seconds: A float, which is the length of the recording
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
        recording_device_name: A string, which is the name of the
                               recording device
    &#34;&#34;&#34;
    if atype is None:
        atype = &#39;int16&#39;
    cmd = [SOX_PATH, f&#39;-b {convert_atype_to_width(atype) * 8}&#39;,
           &#39;-c 1&#39;, f&#39;-r {rate}&#39;, f&#39;-t waveaudio {recording_device_name}&#39;,
           &#39;-e signed-integer&#39;]
    cmd += [f&#39;&#34;{filename}&#34;&#39;]
    cmd += [f&#39;trim 0 {seconds}&#39;]
    subprocess.run(&#39; &#39;.join(cmd), stdout=subprocess.DEVNULL,
                   stderr=subprocess.DEVNULL)


def record(seconds, rate, atype=None, recording_device_name=&#39;Microphone&#39;):
    &#34;&#34;&#34;Records audio from the recording device.

    Args:
        seconds: A float, which is the length of the recording
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
        recording_device_name: A string, which is the name of the
                               recording device

    Returns:
        A tuple of the loaded audio, rate, and atype
    &#34;&#34;&#34;
    global CHUNK, USE_PYAUDIO
    if atype is None:
        atype = &#39;int16&#39;
    if USE_PYAUDIO:
        p = pyaudio.PyAudio()

        if atype == &#39;int16&#39;:
            patype = pyaudio.paInt16
        elif atype == &#39;int8&#39;:
            patype = pyaudio.paInt8
        else:
            raise ValueError(&#39;Supported atypes are either int8 or int16&#39;)
        stream = p.open(format=patype,
                        channels=1,
                        rate=rate,
                        input=True,
                        frames_per_buffer=CHUNK)

        frames = []
        for i in range(0, int(rate / CHUNK * seconds)):
            frames.append(stream.read(CHUNK))

        stream.stop_stream()
        stream.close()
        p.terminate()
        audio = (np.frombuffer(b&#39;&#39;.join(frames), dtype=atype) /
                 np.iinfo(atype).max)
    else:
        temp_filename = os.path.join(
            util_dir, str(np.random.randint(10000, 100000))+&#39;.wav&#39;
        )
        file_record(temp_filename, seconds, rate, atype=atype,
                    recording_device_name=recording_device_name)
        try:
            with wave.open(temp_filename, &#39;r&#39;) as file:
                atype = convert_width_to_atype(file.getsampwidth())
                rate = file.getframerate()
                audio = file.readframes(file.getnframes())
                audio = np.frombuffer(audio, dtype=atype) / np.iinfo(atype).max
        finally:
            os.remove(temp_filename)
    return audio, rate, atype


def file_play(filename):
    &#34;&#34;&#34;Plays the audio file.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
    &#34;&#34;&#34;
    cmd = [SOX_PATH, f&#39;&#34;{filename}&#34;&#39;, &#39;-t waveaudio&#39;]
    subprocess.run(&#39; &#39;.join(cmd), stdout=subprocess.DEVNULL,
                   stderr=subprocess.DEVNULL)


def play(audio, rate, atype=None):
    &#34;&#34;&#34;Plays the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
    &#34;&#34;&#34;
    global CHUNK, USE_PYAUDIO
    if atype is None:
        atype = &#39;int16&#39;
    if USE_PYAUDIO:
        p = pyaudio.PyAudio()

        if atype == &#39;int16&#39;:
            patype = pyaudio.paInt16
        elif atype == &#39;int8&#39;:
            patype = pyaudio.paInt8
        else:
            raise ValueError(&#39;Supported atypes are either int8 or int16&#39;)
        stream = p.open(format=patype,
                        channels=1,
                        rate=rate,
                        output=True)

        audio = (audio * np.iinfo(atype).max).astype(atype)
        data = np.array_split(audio, CHUNK)
        for frame in data:
            stream.write(frame.tobytes())

        stream.stop_stream()
        stream.close()
        p.terminate()
    else:
        temp_filename = os.path.join(
            util_dir, str(np.random.randint(10000, 100000)) + &#39;.wav&#39;
        )
        audio = np.pad(audio, (0, rate), &#39;constant&#39;)
        save(temp_filename, audio, rate, atype=atype)
        try:
            file_play(temp_filename)
        finally:
            os.remove(temp_filename)


def calc_duration(audio, rate):
    &#34;&#34;&#34;Calculates the length of the audio in seconds.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken

    Returns:
        A float
    &#34;&#34;&#34;
    return audio.size / rate


def set_length(audio, length, mode=&#39;R&#39;, pad_value=0):
    &#34;&#34;&#34;Sets the length of audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        length: An integer, which is the length to set the audio to
        mode: A string (&#39;L&#39;,&#39;R&#39;,&#39;B&#39;), which determines where to pad or remove
        pad_values: A float within -1.0 to 1.0 (inclusive), which will be
                    the if the audio is padded

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    mode = mode.lower()
    assert mode in &#39;lbr&#39;, &#39;mode must be L(Left), R(Right), or B(Both)&#39;
    size = audio.size
    if size &gt; length:
        if mode == &#39;l&#39;:
            return audio[size-length:]
        elif mode == &#39;r&#39;:
            return audio[:length-size]
        else:
            return audio[(size-length)//2:-(size-length)//2]
    else:
        if mode == &#39;l&#39;:
            return np.pad(audio, (length-size, 0),
                          &#39;constant&#39;, constant_values=pad_value)
        elif mode == &#39;r&#39;:
            return np.pad(audio, (0, length-size),
                          &#39;constant&#39;, constant_values=pad_value)
        else:
            return np.pad(audio, ((length-size)//2, (length-size+1)//2),
                          &#39;constant&#39;, constant_values=pad_value)


def set_duration(audio, rate, seconds, mode=&#39;R&#39;, pad_value=0):
    &#34;&#34;&#34;Sets the duration of audio in seconds.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        seconds: A float, which is the duration to set the audio to
        mode: A string (&#39;L&#39;,&#39;R&#39;,&#39;B&#39;), which determines where to pad or remove
        pad_values: A float within -1.0 to 1.0 (inclusive), which will be
                    the value if the audio is padded

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    return set_length(audio, round(rate * seconds), mode, pad_value)


def for_each_frame(audio, rate, frame_duration, func):
    &#34;&#34;&#34;Calls a function on each frame.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
        func: A function, which takes a frame and returns a value

    Returns:
        A tuple of a numpy ndarray of results from func and integer
            (new rate)
    &#34;&#34;&#34;
    frames = np.array_split(
        audio, int(audio.size / (rate * frame_duration))
    )
    audio = np.array([func(frame) for frame in frames])
    return audio, round(1 / frame_duration)


def compute_spectrogram(audio, rate, frame_duration, real=True):
    &#34;&#34;&#34;Computes a nonoverlapping spectrogram.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
        real: A boolean, which determines if one side hermitian ffts
              should be used or real ffts

    Returns:
        A tuple of a numpy ndarray, which has 2 dimensions
            (frame, frequency powers), and an integer (new rate)
    &#34;&#34;&#34;
    if real:
        def ft(frame):
            x = np.fft.hfft(frame)
            return x[:len(x) // 2 + 1]
    else:
        def ft(frame):
            return np.fft.rfft(frame)
    return for_each_frame(audio, rate, frame_duration, ft)


def convert_spectrogram_to_audio(spectrogram, rate, real=True):
    &#34;&#34;&#34;Converts a nonoverlapping spectrogram back to audio.

    Args:
        spectrogram: A numpy ndarray, which has 2 dimensions
        rate: An integer, which is the rate at which each frame is taken
        real: A boolean, which determines if one side hermitian ffts
              should be used or real ffts

    Returns:
        A tuple of a numpy ndarray, which has 1 dimension,
            and an integer (new rate)
    &#34;&#34;&#34;
    if real:
        def ft(frame):
            frame2 = np.hstack([frame, np.flip(frame[1:-1])])
            return np.real(np.fft.ihfft(frame2))
    else:
        def ft(frame):
            return np.fft.irfft(frame)
    frames = []
    for frame in spectrogram:
        frames.append(ft(frame))
    return np.hstack(frames), len(frames[0]) * rate


def compute_fbank(signal, samplerate=16000, winlen=0.025, winstep=0.01,
                  nfilt=26, nfft=512, lowfreq=0, highfreq=None, preemph=0.97,
                  winfunc=lambda x: np.ones((x,))):
    &#34;&#34;&#34;Compute Mel-filterbank energy features from an audio signal.
    Code adapted from python_speech_features, written orginally by James Lyons.

    Args:
        signal: the audio signal from which to compute features.
                Should be an N*1 array
        samplerate: the sample rate of the signal we are working with, in Hz.
        winlen: the length of the analysis window in seconds. Default is
                0.025s (25 milliseconds)
        winstep: the step between successive windows in seconds. Default
                 is 0.01s (10 milliseconds)
        nfilt: the number of filters in the filterbank, default 26.
        nfft: the FFT size. Default is None, which uses the calculate_nfft
              function to choose the smallest size that does not drop
              sample data.
        lowfreq: lowest band edge of mel filters. In Hz, default is 0.
        highfreq: highest band edge of mel filters. In Hz, default
                  is samplerate/2
        preemph: apply preemphasis filter with preemph as coefficient.
                 0 is no filter. Default is 0.97.
        winfunc: the analysis window to apply to each frame. By default
                 no window is applied. You can use numpy window functions
                 here e.g. winfunc=numpy.hamming

    Returns:
        2 values. The first is a numpy array of size (NUMFRAMES by nfilt)
            containing features. Each row holds 1 feature vector. The
            second return value is the energy in each frame
            (total energy, unwindowed)
    &#34;&#34;&#34;
    highfreq = highfreq or samplerate / 2
    assert highfreq &lt;= samplerate / 2, \
        &#39;highfreq is greater than samplerate / 2&#39;
    signal = np.append(signal[0], signal[1:] - preemph * signal[:-1])

    slen = len(signal)
    frame_len = int(winlen * samplerate + .5)
    frame_step = int(winstep * samplerate + .5)
    num_frames = 1
    if slen &gt; frame_len:
        num_frames += int(np.ceil((slen - frame_len) / frame_step))
    pad_len = int((num_frames - 1) * frame_step + frame_len)
    padded_signal = np.concatenate([signal, np.zeros(pad_len - slen)])
    frames = np.lib.stride_tricks.as_strided(
        padded_signal,
        shape=padded_signal.shape[:-1] +
        (padded_signal.shape[-1] - frame_len + 1, frame_len),
        strides=padded_signal.strides + (padded_signal.strides[-1],)
    )[::frame_step] * winfunc(frame_len)
    pspec = 1.0 / nfft * np.square(np.abs(np.fft.rfft(frames, nfft)))
    energy = np.sum(pspec, 1)
    energy = np.where(energy == 0, np.finfo(float).eps, energy)

    lowmel = 2595 * np.log10(1 + lowfreq / 700)
    highmel = 2595 * np.log10(1 + highfreq / 700)
    melpoints = np.linspace(lowmel, highmel, nfilt + 2)
    fft_bins = np.floor(
        (nfft + 1) * (700 * (10**(melpoints / 2595) - 1)) / samplerate
    )
    fbank = np.zeros([nfilt, nfft//2+1])
    for j in range(0, nfilt):
        for i in range(int(fft_bins[j]), int(fft_bins[j+1])):
            fbank[j, i] = (i - fft_bins[j]) / (fft_bins[j+1]-fft_bins[j])
        for i in range(int(fft_bins[j+1]), int(fft_bins[j+2])):
            fbank[j, i] = (fft_bins[j+2]-i) / (fft_bins[j+2]-fft_bins[j+1])
    feat = np.dot(pspec, fbank.T)
    feat = np.where(feat == 0, np.finfo(float).eps, feat)
    return feat, energy


def compute_mfcc(signal, samplerate=16000, winlen=0.025,
                 winstep=0.01, numcep=13, nfilt=26, nfft=None,
                 lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22,
                 append_energy=True, winfunc=lambda x: np.ones((x,))):
    &#34;&#34;&#34;Computes MFCC features from an audio signal.
    Code adapted from python_speech_features, written orginally by James Lyons.

    Args:
        signal: the audio signal from which to compute features.
                Should be an N*1 array
        samplerate: the sample rate of the signal we are working with, in Hz.
        winlen: the length of the analysis window in seconds. Default is
                0.025s (25 milliseconds)
        winstep: the step between successive windows in seconds. Default
                 is 0.01s (10 milliseconds)
        numcep: the number of cepstrum to return, default 13
        nfilt: the number of filters in the filterbank, default 26.
        nfft: the FFT size. Default is None, which uses the calculate_nfft
              function to choose the smallest size that does not drop
              sample data.
        lowfreq: lowest band edge of mel filters. In Hz, default is 0.
        highfreq: highest band edge of mel filters. In Hz, default is
                  samplerate/2
        preemph: apply preemphasis filter with preemph as coefficient.
                 0 is no filter. Default is 0.97.
        ceplifter: apply a lifter to final cepstral coefficients.
                   0 is no lifter. Default is 22.
        append_energy: if this is true, the zeroth cepstral coefficient is
                       replaced with the log of the total frame energy.
        winfunc: the analysis window to apply to each frame. By default
                 no window is applied. You can use numpy window functions
                 here e.g. winfunc=numpy.hamming

    Returns:
        A numpy array of size (NUMFRAMES by numcep) containing features.
            Each row holds 1 feature vector.
    &#34;&#34;&#34;
    if nfft is None:
        winlen_samples = winlen * samplerate
        nfft = 1
        while nfft &lt; winlen_samples:
            nfft *= 2
    feat, energy = compute_fbank(signal, samplerate, winlen, winstep, nfilt,
                                 nfft, lowfreq, highfreq, preemph, winfunc)
    feat = np.log(feat)
    feat = dct(feat, type=2, axis=1, norm=&#39;ortho&#39;)[:, :numcep]
    if ceplifter &gt; 0:
        feat = feat * (1 + (ceplifter / 2) *
                       np.sin((np.pi / ceplifter) * np.arange(feat.shape[1])))
    if append_energy:
        feat[:, 0] = np.log(energy)
    return feat


def calc_rms(audio):
    &#34;&#34;&#34;Calculates the Root Mean Square of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)

    Returns:
        A float, which is the rms of the audio
    &#34;&#34;&#34;
    return np.sqrt(np.sum(np.square(audio)) / audio.size)


def shift_pitch(audio, rate, steps):
    &#34;&#34;&#34;Shifts the pitch of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    y = np.fft.rfft(audio)
    y = np.roll(y, steps)
    if steps &gt; 0:
        y[:steps] = 0
    else:
        y[steps:] = 0
    return np.fft.irfft(y, audio.size)


def set_power(audio, power):
    &#34;&#34;&#34;Sets the power of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        power: A float, which is the Root Mean Square to set the audio to

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    return np.clip(power / calc_rms(audio) * audio, -1, 1)


def adjust_speed(audio, rate, multiplier=1):
    &#34;&#34;&#34;Adjusts the speed of the audio and keeps the RMS power the same.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        multiplier: A float, which is the amount to adjust the relative speed

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    power = calc_rms(audio)
    y = np.fft.rfft(audio)
    ns = round(audio.size / multiplier)
    return set_power(np.fft.irfft(y, ns), power)


def set_speed(audio, rate, seconds):
    &#34;&#34;&#34;Sets the speed of the audio and keeps the RMS power the same.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        seconds: A float, which is the number of seconds the audio
                 should be set to

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    power = calc_rms(audio)
    y = np.fft.rfft(audio)
    ns = round(seconds * rate)
    return set_power(np.fft.irfft(y, ns), power)


def adjust_volume(audio, multiplier=1):
    &#34;&#34;&#34;Adjusts the volume of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        multiplier: A float, which is the amount to adjust the relative volume

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    return np.clip(audio * multiplier, -1, 1)


def blend(audio1, audio2, audio1_weight=.5, audio2_weight=None):
    &#34;&#34;&#34;Blends two audios together.

    Args:
        audio1: A numpy ndarray, which has 1 dimension and values within
                -1.0 to 1.0 (inclusive)
        audio2: A numpy ndarray, which has 1 dimension and values within
                -1.0 to 1.0 (inclusive)
        audio1_weight: A float, which is the weight of audio 1
                       and should be within 0.0 and 1.0 (exclusive)
        audio2_weight: A float, which is the weight of audio 2
                       and should be within 0.0 and 1.0 (exclusive)

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    if audio2_weight is None:
        audio2_weight = 1 - audio1_weight
    if audio1.size == audio2.size:
        return audio1 * audio1_weight + audio2 * audio2_weight
    elif audio1.size &gt; audio2.size:
        audio1 = audio1 * audio1_weight
        return np.hstack((audio1[:audio2.size] + audio2_weight * audio2,
                          audio1[audio2.size:]))
    else:
        audio2 = audio2 * audio2_weight
        return np.hstack((audio1 * audio1_weight + audio2[audio1.size:],
                          audio2[audio1.size:]))


def plot(audio, seconds=0):
    &#34;&#34;&#34;Plots the audio on a graph.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        seconds: A float, which is the number of seconds to show the plot
    &#34;&#34;&#34;
    plt.plot(audio)
    if seconds == 0:
        plt.show()
    else:
        plt.show(block=False)
        plt.pause(seconds)
        plt.close()


def convert_audio_to_db(audio, rate, frame_duration, ref_func=lambda x: 1,
                        min_threshold=1e-10, db_threshold=80.0):
    &#34;&#34;&#34;Converts the audio to decibels.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
        ref_func: A function, which takes a magnitude and returns a value
        min_threshold: A float, which is the minimum magnitude
        db_threshold: A float, which is the threshold for the audio
                      in decibels

    Returns:
        A tuple of a numpy ndarray, which has 1 dimension,
            and an integer (new rate)
    &#34;&#34;&#34;
    mag, new_rate = for_each_frame(audio, rate, frame_duration,
                                   lambda sample: calc_rms(sample))
    y = 10.0 * np.log10(np.maximum(min_threshold, mag))
    y -= 10.0 * np.log10(np.maximum(min_threshold, ref_func(mag)))
    y = y if db_threshold is None else np.maximum(y, y.max() - db_threshold)
    return y, new_rate


def convert_power_to_db(power, ref_func=lambda x: 1,
                        min_threshold=1e-10, db_threshold=80.0):
    &#34;&#34;&#34;Converts power to decibels.

    Args:
        power: A numpy ndarray, which has 1 or 2 dimensions
        min_threshold: A float, which is the minimum magnitude
        db_threshold: A float, which is the threshold for the audio
                in decibels

    Returns:
        A numpy ndarray, which has 1 or 2 dimensions
    &#34;&#34;&#34;
    mag = np.abs(power)
    y = 10.0 * np.log10(np.maximum(min_threshold, mag))
    y -= 10.0 * np.log10(np.maximum(min_threshold, ref_func(mag)))
    y = y if db_threshold is None else np.maximum(y, y.max() - db_threshold)
    return y


def convert_amplitude_to_db(amplitude, ref_func=lambda x: 1,
                            min_threshold=1e-10, db_threshold=80.0):
    &#34;&#34;&#34;Converts amplitude to decibels.

    Args:
        amplitude: A numpy ndarray, which has 1 or 2 dimensions
        min_threshold: A float, which is the minimum magnitude
        db_threshold: A float, which is the threshold for the audio
                in decibels

    Returns:
        A numpy ndarray, which has 1 or 2 dimensions
    &#34;&#34;&#34;
    mag = np.abs(amplitude)
    y = 20.0 * np.log10(np.maximum(min_threshold, mag))
    y -= 20.0 * np.log10(np.maximum(min_threshold, ref_func(mag)))
    y = y if db_threshold is None else np.maximum(y, y.max() - db_threshold)
    return y


def trim_all(audio, rate, frame_duration, ambient_power=1e-4):
    &#34;&#34;&#34;Trims ambient silence in the audio anywhere.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    new_audio = []
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power:
            new_audio += audio[ndx*frame_length:(ndx+1)*frame_length].tolist()
    return np.array(new_audio)


def trim_sides(audio, rate, frame_duration, ambient_power=1e-4):
    &#34;&#34;&#34;Trims ambient silence in the audio only on the sides.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    start_ndx = None
    end_ndx = None
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power and start_ndx is None:
            start_ndx = ndx * frame_length
            break
    else:
        start_ndx = 0
    for ndx, power in enumerate(reversed(powers)):
        if power &gt; ambient_power and end_ndx is None:
            end_ndx = (len(powers) - ndx) * frame_length
            break
    else:
        end_ndx = len(audio)
    if start_ndx &lt; end_ndx:
        return audio[start_ndx:end_ndx]
    return audio


def split(audio, rate, frame_duration, ambient_power=1e-4, min_gap=None):
    &#34;&#34;&#34;Splits the audio into audio segments on ambient frames.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise
        min_gap: An integer, which is the number of frames to consider until
                 ambient frames are removed

    Returns:
        A list of numpy ndarray, which are 1 dimension each and have
            values within -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    if min_gap is None:
        min_gap = frame_duration
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    audios = []
    last_split = 0
    gap = 0
    on = False
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power:
            gap = 0
            on = True
        else:
            gap += frame_duration
            if gap &gt;= min_gap and on:
                gap = 0
                on = False
                next_split = (ndx + 1) * frame_length
                audios.append(audio[last_split:next_split])
                last_split = next_split
    return audios


def find_gaps(audio, rate, frame_duration, ambient_power=1e-4):
    &#34;&#34;&#34;Finds the length of gaps in the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise

    Returns:
        A list of tuples with the first value in the tuple being the start
            of a gap and the second value the end
    &#34;&#34;&#34;
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    gaps = []
    start = None
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power:
            if start is not None:
                end = (ndx + 1) * frame_length
                gaps.append((start, end))
            start = None
        elif start is None:
            start = ndx * frame_length
    if start is not None:
        gaps.append((start, len(audio)))
    return gaps


def vad_trim_all(audio, rate, frame_duration, aggressiveness=1):
    &#34;&#34;&#34;Trims anywhere in the audio that does not contain speech.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer (8000, 16000, 32000, 48000), which is the rate
              at which samples are taken
        frame_duration: A float (.01, .02, .03), which is the duration
                        of each frame to check
        aggressiveness: A integer (0, 1, 2, 3), which is the level of
                        aggressiveness to trim non-speech

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    assert rate in (8000, 16000, 32000, 48000), (
        &#39;Invalid Rate, use 8000, 16000, 32000, or 48000&#39;
    )
    assert frame_duration in (.01, .02, .03), (
        &#39;Invalid frame_dur, use .01, .02, .03&#39;
    )
    assert 0 &lt;= aggressiveness &lt;= 3, (
        &#39;Invalid aggressiveness, must be between 0 and 3&#39;
    )

    audio = (audio * np.iinfo(&#39;int16&#39;).max).astype(&#39;int16&#39;)

    vad = webrtcvad.Vad(aggressiveness)
    frame_size = int(rate * frame_duration)
    offset = 0
    voiced_frames = []
    while offset + frame_size &lt; len(audio):
        frame = audio[offset:offset + frame_size]
        if vad.is_speech(frame.tobytes(), rate):
            voiced_frames.append(frame)
        offset += frame_size
    if len(voiced_frames) == 0:
        return audio
    return np.hstack(voiced_frames)


def vad_trim_sides(audio, rate, frame_duration, aggressiveness=1):
    &#34;&#34;&#34;Trims the sides in the audio that do not contain speech.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer (8000, 16000, 32000, 48000), which is the rate
              at which samples are taken
        frame_duration: A float (.01, .02, .03), which is the duration
                        of each frame to check
        aggressiveness: A integer (0, 1, 2, 3), which is the level of
                        aggressiveness to trim non-speech

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    assert rate in (8000, 16000, 32000, 48000), (
        &#39;Invalid Rate, use 8000, 16000, 32000, or 48000&#39;
    )
    assert frame_duration in (.01, .02, .03), (
        &#39;Invalid frame_dur, use .01, .02, .03&#39;
    )
    assert 0 &lt;= aggressiveness &lt;= 3, (
        &#39;Invalid aggressiveness, must be between 0 and 3&#39;
    )

    audio = (audio * np.iinfo(&#39;int16&#39;).max).astype(&#39;int16&#39;)

    vad = webrtcvad.Vad(aggressiveness)
    frame_size = int(rate * frame_duration)
    offset = 0
    start_ndx = 0
    while offset + frame_size &lt; len(audio):
        frame = audio[offset:offset + frame_size]
        if vad.is_speech(frame.tobytes(), rate):
            start_ndx = offset
            break
        offset += frame_size
    else:
        return audio
    offset = len(audio)
    end_ndx = len(audio)
    while offset - frame_size &gt; start_ndx:
        frame = audio[offset - frame_size:offset]
        if vad.is_speech(frame.tobytes(), rate):
            end_ndx = offset
            break
        offset -= frame_size
    return audio[start_ndx:end_ndx]


def vad_split(audio, rate, frame_duration, aggressiveness=1):
    &#34;&#34;&#34;Splits the audio into audio segments on non-speech frames.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check

    Returns:
        A list of numpy ndarray, which are 1 dimension each and
            have values within -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    assert rate in (8000, 16000, 32000, 48000), (
        &#39;Invalid Rate, use 8000, 16000, 32000, or 48000&#39;
    )
    assert frame_duration in (.01, .02, .03), (
        &#39;Invalid frame_dur, use .01, .02, .03&#39;
    )
    assert 0 &lt;= aggressiveness &lt;= 3, (
        &#39;Invalid aggressiveness, must be between 0 and 3&#39;
    )

    audio = (audio * np.iinfo(&#39;int16&#39;).max).astype(&#39;int16&#39;)

    vad = webrtcvad.Vad(aggressiveness)
    frame_size = int(rate * frame_duration)
    offset = 0
    off = True
    voiced_frames = []
    while offset + frame_size &lt; len(audio):
        frame = audio[offset:offset + frame_size]
        if vad.is_speech(frame.tobytes(), rate):
            if off is True:
                off = False
                voiced_frames.append([frame])
            else:
                voiced_frames[-1].append(frame)
        else:
            off = True
        offset += frame_size
    if len(voiced_frames) == 0:
        return np.array([audio])
    for ndx in range(len(voiced_frames)):
        voiced_frames[ndx] = np.hstack(voiced_frames[ndx])
    return voiced_frames</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="paiutils.audio.adjust_speed"><code class="name flex">
<span>def <span class="ident">adjust_speed</span></span>(<span>audio, rate, multiplier=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Adjusts the speed of the audio and keeps the RMS power the same.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>multiplier</code></strong></dt>
<dd>A float, which is the amount to adjust the relative speed</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_speed(audio, rate, multiplier=1):
    &#34;&#34;&#34;Adjusts the speed of the audio and keeps the RMS power the same.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        multiplier: A float, which is the amount to adjust the relative speed

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    power = calc_rms(audio)
    y = np.fft.rfft(audio)
    ns = round(audio.size / multiplier)
    return set_power(np.fft.irfft(y, ns), power)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.adjust_volume"><code class="name flex">
<span>def <span class="ident">adjust_volume</span></span>(<span>audio, multiplier=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Adjusts the volume of the audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>multiplier</code></strong></dt>
<dd>A float, which is the amount to adjust the relative volume</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_volume(audio, multiplier=1):
    &#34;&#34;&#34;Adjusts the volume of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        multiplier: A float, which is the amount to adjust the relative volume

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    return np.clip(audio * multiplier, -1, 1)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.blend"><code class="name flex">
<span>def <span class="ident">blend</span></span>(<span>audio1, audio2, audio1_weight=0.5, audio2_weight=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Blends two audios together.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio1</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>audio2</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>audio1_weight</code></strong></dt>
<dd>A float, which is the weight of audio 1
and should be within 0.0 and 1.0 (exclusive)</dd>
<dt><strong><code>audio2_weight</code></strong></dt>
<dd>A float, which is the weight of audio 2
and should be within 0.0 and 1.0 (exclusive)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def blend(audio1, audio2, audio1_weight=.5, audio2_weight=None):
    &#34;&#34;&#34;Blends two audios together.

    Args:
        audio1: A numpy ndarray, which has 1 dimension and values within
                -1.0 to 1.0 (inclusive)
        audio2: A numpy ndarray, which has 1 dimension and values within
                -1.0 to 1.0 (inclusive)
        audio1_weight: A float, which is the weight of audio 1
                       and should be within 0.0 and 1.0 (exclusive)
        audio2_weight: A float, which is the weight of audio 2
                       and should be within 0.0 and 1.0 (exclusive)

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    if audio2_weight is None:
        audio2_weight = 1 - audio1_weight
    if audio1.size == audio2.size:
        return audio1 * audio1_weight + audio2 * audio2_weight
    elif audio1.size &gt; audio2.size:
        audio1 = audio1 * audio1_weight
        return np.hstack((audio1[:audio2.size] + audio2_weight * audio2,
                          audio1[audio2.size:]))
    else:
        audio2 = audio2 * audio2_weight
        return np.hstack((audio1 * audio1_weight + audio2[audio1.size:],
                          audio2[audio1.size:]))</code></pre>
</details>
</dd>
<dt id="paiutils.audio.calc_duration"><code class="name flex">
<span>def <span class="ident">calc_duration</span></span>(<span>audio, rate)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the length of the audio in seconds.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A float</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_duration(audio, rate):
    &#34;&#34;&#34;Calculates the length of the audio in seconds.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken

    Returns:
        A float
    &#34;&#34;&#34;
    return audio.size / rate</code></pre>
</details>
</dd>
<dt id="paiutils.audio.calc_rms"><code class="name flex">
<span>def <span class="ident">calc_rms</span></span>(<span>audio)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the Root Mean Square of the audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A float, which is the rms of the audio</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_rms(audio):
    &#34;&#34;&#34;Calculates the Root Mean Square of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)

    Returns:
        A float, which is the rms of the audio
    &#34;&#34;&#34;
    return np.sqrt(np.sum(np.square(audio)) / audio.size)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.change_rate"><code class="name flex">
<span>def <span class="ident">change_rate</span></span>(<span>audio, rate, new_rate, atype=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Changes the audio's sample rate.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>new_rate</code></strong></dt>
<dd>An integer, which is the rate to change the audio to</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of the loaded audio, rate, and atype</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def change_rate(audio, rate, new_rate, atype=None):
    &#34;&#34;&#34;Changes the audio&#39;s sample rate.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        new_rate: An integer, which is the rate to change the audio to

    Returns:
        A tuple of the loaded audio, rate, and atype
    &#34;&#34;&#34;
    if rate == new_rate:
        return audio, rate
    temp_filename = os.path.join(
        util_dir, str(np.random.randint(10000, 100000)) + &#39;.wav&#39;
    )
    save(temp_filename, audio, rate, atype=atype)
    try:
        audio, rate, atype = load(temp_filename, new_rate)
    finally:
        os.remove(temp_filename)
    return audio, rate, atype</code></pre>
</details>
</dd>
<dt id="paiutils.audio.compute_fbank"><code class="name flex">
<span>def <span class="ident">compute_fbank</span></span>(<span>signal, samplerate=16000, winlen=0.025, winstep=0.01, nfilt=26, nfft=512, lowfreq=0, highfreq=None, preemph=0.97, winfunc=&lt;function &lt;lambda&gt;&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute Mel-filterbank energy features from an audio signal.
Code adapted from python_speech_features, written orginally by James Lyons.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>signal</code></strong></dt>
<dd>the audio signal from which to compute features.
Should be an N*1 array</dd>
<dt><strong><code>samplerate</code></strong></dt>
<dd>the sample rate of the signal we are working with, in Hz.</dd>
<dt><strong><code>winlen</code></strong></dt>
<dd>the length of the analysis window in seconds. Default is
0.025s (25 milliseconds)</dd>
<dt><strong><code>winstep</code></strong></dt>
<dd>the step between successive windows in seconds. Default
is 0.01s (10 milliseconds)</dd>
<dt><strong><code>nfilt</code></strong></dt>
<dd>the number of filters in the filterbank, default 26.</dd>
<dt><strong><code>nfft</code></strong></dt>
<dd>the FFT size. Default is None, which uses the calculate_nfft
function to choose the smallest size that does not drop
sample data.</dd>
<dt><strong><code>lowfreq</code></strong></dt>
<dd>lowest band edge of mel filters. In Hz, default is 0.</dd>
<dt><strong><code>highfreq</code></strong></dt>
<dd>highest band edge of mel filters. In Hz, default
is samplerate/2</dd>
<dt><strong><code>preemph</code></strong></dt>
<dd>apply preemphasis filter with preemph as coefficient.
0 is no filter. Default is 0.97.</dd>
<dt><strong><code>winfunc</code></strong></dt>
<dd>the analysis window to apply to each frame. By default
no window is applied. You can use numpy window functions
here e.g. winfunc=numpy.hamming</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>2 values. The first is a numpy array of size (NUMFRAMES by nfilt)
containing features. Each row holds 1 feature vector. The
second return value is the energy in each frame
(total energy, unwindowed)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_fbank(signal, samplerate=16000, winlen=0.025, winstep=0.01,
                  nfilt=26, nfft=512, lowfreq=0, highfreq=None, preemph=0.97,
                  winfunc=lambda x: np.ones((x,))):
    &#34;&#34;&#34;Compute Mel-filterbank energy features from an audio signal.
    Code adapted from python_speech_features, written orginally by James Lyons.

    Args:
        signal: the audio signal from which to compute features.
                Should be an N*1 array
        samplerate: the sample rate of the signal we are working with, in Hz.
        winlen: the length of the analysis window in seconds. Default is
                0.025s (25 milliseconds)
        winstep: the step between successive windows in seconds. Default
                 is 0.01s (10 milliseconds)
        nfilt: the number of filters in the filterbank, default 26.
        nfft: the FFT size. Default is None, which uses the calculate_nfft
              function to choose the smallest size that does not drop
              sample data.
        lowfreq: lowest band edge of mel filters. In Hz, default is 0.
        highfreq: highest band edge of mel filters. In Hz, default
                  is samplerate/2
        preemph: apply preemphasis filter with preemph as coefficient.
                 0 is no filter. Default is 0.97.
        winfunc: the analysis window to apply to each frame. By default
                 no window is applied. You can use numpy window functions
                 here e.g. winfunc=numpy.hamming

    Returns:
        2 values. The first is a numpy array of size (NUMFRAMES by nfilt)
            containing features. Each row holds 1 feature vector. The
            second return value is the energy in each frame
            (total energy, unwindowed)
    &#34;&#34;&#34;
    highfreq = highfreq or samplerate / 2
    assert highfreq &lt;= samplerate / 2, \
        &#39;highfreq is greater than samplerate / 2&#39;
    signal = np.append(signal[0], signal[1:] - preemph * signal[:-1])

    slen = len(signal)
    frame_len = int(winlen * samplerate + .5)
    frame_step = int(winstep * samplerate + .5)
    num_frames = 1
    if slen &gt; frame_len:
        num_frames += int(np.ceil((slen - frame_len) / frame_step))
    pad_len = int((num_frames - 1) * frame_step + frame_len)
    padded_signal = np.concatenate([signal, np.zeros(pad_len - slen)])
    frames = np.lib.stride_tricks.as_strided(
        padded_signal,
        shape=padded_signal.shape[:-1] +
        (padded_signal.shape[-1] - frame_len + 1, frame_len),
        strides=padded_signal.strides + (padded_signal.strides[-1],)
    )[::frame_step] * winfunc(frame_len)
    pspec = 1.0 / nfft * np.square(np.abs(np.fft.rfft(frames, nfft)))
    energy = np.sum(pspec, 1)
    energy = np.where(energy == 0, np.finfo(float).eps, energy)

    lowmel = 2595 * np.log10(1 + lowfreq / 700)
    highmel = 2595 * np.log10(1 + highfreq / 700)
    melpoints = np.linspace(lowmel, highmel, nfilt + 2)
    fft_bins = np.floor(
        (nfft + 1) * (700 * (10**(melpoints / 2595) - 1)) / samplerate
    )
    fbank = np.zeros([nfilt, nfft//2+1])
    for j in range(0, nfilt):
        for i in range(int(fft_bins[j]), int(fft_bins[j+1])):
            fbank[j, i] = (i - fft_bins[j]) / (fft_bins[j+1]-fft_bins[j])
        for i in range(int(fft_bins[j+1]), int(fft_bins[j+2])):
            fbank[j, i] = (fft_bins[j+2]-i) / (fft_bins[j+2]-fft_bins[j+1])
    feat = np.dot(pspec, fbank.T)
    feat = np.where(feat == 0, np.finfo(float).eps, feat)
    return feat, energy</code></pre>
</details>
</dd>
<dt id="paiutils.audio.compute_mfcc"><code class="name flex">
<span>def <span class="ident">compute_mfcc</span></span>(<span>signal, samplerate=16000, winlen=0.025, winstep=0.01, numcep=13, nfilt=26, nfft=None, lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22, append_energy=True, winfunc=&lt;function &lt;lambda&gt;&gt;)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes MFCC features from an audio signal.
Code adapted from python_speech_features, written orginally by James Lyons.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>signal</code></strong></dt>
<dd>the audio signal from which to compute features.
Should be an N*1 array</dd>
<dt><strong><code>samplerate</code></strong></dt>
<dd>the sample rate of the signal we are working with, in Hz.</dd>
<dt><strong><code>winlen</code></strong></dt>
<dd>the length of the analysis window in seconds. Default is
0.025s (25 milliseconds)</dd>
<dt><strong><code>winstep</code></strong></dt>
<dd>the step between successive windows in seconds. Default
is 0.01s (10 milliseconds)</dd>
<dt><strong><code>numcep</code></strong></dt>
<dd>the number of cepstrum to return, default 13</dd>
<dt><strong><code>nfilt</code></strong></dt>
<dd>the number of filters in the filterbank, default 26.</dd>
<dt><strong><code>nfft</code></strong></dt>
<dd>the FFT size. Default is None, which uses the calculate_nfft
function to choose the smallest size that does not drop
sample data.</dd>
<dt><strong><code>lowfreq</code></strong></dt>
<dd>lowest band edge of mel filters. In Hz, default is 0.</dd>
<dt><strong><code>highfreq</code></strong></dt>
<dd>highest band edge of mel filters. In Hz, default is
samplerate/2</dd>
<dt><strong><code>preemph</code></strong></dt>
<dd>apply preemphasis filter with preemph as coefficient.
0 is no filter. Default is 0.97.</dd>
<dt><strong><code>ceplifter</code></strong></dt>
<dd>apply a lifter to final cepstral coefficients.
0 is no lifter. Default is 22.</dd>
<dt><strong><code>append_energy</code></strong></dt>
<dd>if this is true, the zeroth cepstral coefficient is
replaced with the log of the total frame energy.</dd>
<dt><strong><code>winfunc</code></strong></dt>
<dd>the analysis window to apply to each frame. By default
no window is applied. You can use numpy window functions
here e.g. winfunc=numpy.hamming</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy array of size (NUMFRAMES by numcep) containing features.
Each row holds 1 feature vector.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_mfcc(signal, samplerate=16000, winlen=0.025,
                 winstep=0.01, numcep=13, nfilt=26, nfft=None,
                 lowfreq=0, highfreq=None, preemph=0.97, ceplifter=22,
                 append_energy=True, winfunc=lambda x: np.ones((x,))):
    &#34;&#34;&#34;Computes MFCC features from an audio signal.
    Code adapted from python_speech_features, written orginally by James Lyons.

    Args:
        signal: the audio signal from which to compute features.
                Should be an N*1 array
        samplerate: the sample rate of the signal we are working with, in Hz.
        winlen: the length of the analysis window in seconds. Default is
                0.025s (25 milliseconds)
        winstep: the step between successive windows in seconds. Default
                 is 0.01s (10 milliseconds)
        numcep: the number of cepstrum to return, default 13
        nfilt: the number of filters in the filterbank, default 26.
        nfft: the FFT size. Default is None, which uses the calculate_nfft
              function to choose the smallest size that does not drop
              sample data.
        lowfreq: lowest band edge of mel filters. In Hz, default is 0.
        highfreq: highest band edge of mel filters. In Hz, default is
                  samplerate/2
        preemph: apply preemphasis filter with preemph as coefficient.
                 0 is no filter. Default is 0.97.
        ceplifter: apply a lifter to final cepstral coefficients.
                   0 is no lifter. Default is 22.
        append_energy: if this is true, the zeroth cepstral coefficient is
                       replaced with the log of the total frame energy.
        winfunc: the analysis window to apply to each frame. By default
                 no window is applied. You can use numpy window functions
                 here e.g. winfunc=numpy.hamming

    Returns:
        A numpy array of size (NUMFRAMES by numcep) containing features.
            Each row holds 1 feature vector.
    &#34;&#34;&#34;
    if nfft is None:
        winlen_samples = winlen * samplerate
        nfft = 1
        while nfft &lt; winlen_samples:
            nfft *= 2
    feat, energy = compute_fbank(signal, samplerate, winlen, winstep, nfilt,
                                 nfft, lowfreq, highfreq, preemph, winfunc)
    feat = np.log(feat)
    feat = dct(feat, type=2, axis=1, norm=&#39;ortho&#39;)[:, :numcep]
    if ceplifter &gt; 0:
        feat = feat * (1 + (ceplifter / 2) *
                       np.sin((np.pi / ceplifter) * np.arange(feat.shape[1])))
    if append_energy:
        feat[:, 0] = np.log(energy)
    return feat</code></pre>
</details>
</dd>
<dt id="paiutils.audio.compute_spectrogram"><code class="name flex">
<span>def <span class="ident">compute_spectrogram</span></span>(<span>audio, rate, frame_duration, real=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes a nonoverlapping spectrogram.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame</dd>
<dt><strong><code>real</code></strong></dt>
<dd>A boolean, which determines if one side hermitian ffts
should be used or real ffts</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of a numpy ndarray, which has 2 dimensions
(frame, frequency powers), and an integer (new rate)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_spectrogram(audio, rate, frame_duration, real=True):
    &#34;&#34;&#34;Computes a nonoverlapping spectrogram.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
        real: A boolean, which determines if one side hermitian ffts
              should be used or real ffts

    Returns:
        A tuple of a numpy ndarray, which has 2 dimensions
            (frame, frequency powers), and an integer (new rate)
    &#34;&#34;&#34;
    if real:
        def ft(frame):
            x = np.fft.hfft(frame)
            return x[:len(x) // 2 + 1]
    else:
        def ft(frame):
            return np.fft.rfft(frame)
    return for_each_frame(audio, rate, frame_duration, ft)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.convert_amplitude_to_db"><code class="name flex">
<span>def <span class="ident">convert_amplitude_to_db</span></span>(<span>amplitude, ref_func=&lt;function &lt;lambda&gt;&gt;, min_threshold=1e-10, db_threshold=80.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts amplitude to decibels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>amplitude</code></strong></dt>
<dd>A numpy ndarray, which has 1 or 2 dimensions</dd>
<dt><strong><code>min_threshold</code></strong></dt>
<dd>A float, which is the minimum magnitude</dd>
<dt><strong><code>db_threshold</code></strong></dt>
<dd>A float, which is the threshold for the audio
in decibels</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 or 2 dimensions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_amplitude_to_db(amplitude, ref_func=lambda x: 1,
                            min_threshold=1e-10, db_threshold=80.0):
    &#34;&#34;&#34;Converts amplitude to decibels.

    Args:
        amplitude: A numpy ndarray, which has 1 or 2 dimensions
        min_threshold: A float, which is the minimum magnitude
        db_threshold: A float, which is the threshold for the audio
                in decibels

    Returns:
        A numpy ndarray, which has 1 or 2 dimensions
    &#34;&#34;&#34;
    mag = np.abs(amplitude)
    y = 20.0 * np.log10(np.maximum(min_threshold, mag))
    y -= 20.0 * np.log10(np.maximum(min_threshold, ref_func(mag)))
    y = y if db_threshold is None else np.maximum(y, y.max() - db_threshold)
    return y</code></pre>
</details>
</dd>
<dt id="paiutils.audio.convert_atype_to_width"><code class="name flex">
<span>def <span class="ident">convert_atype_to_width</span></span>(<span>atype)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts an audio type to the number of bytes each value takes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>atype</code></strong></dt>
<dd>A string, which is an audio type</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An integer, which is the number of bytes wide</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_atype_to_width(atype):
    &#34;&#34;&#34;Converts an audio type to the number of bytes each value takes.

    Args:
        atype: A string, which is an audio type

    Returns:
        An integer, which is the number of bytes wide
    &#34;&#34;&#34;
    if atype == &#39;int8&#39;:
        return 1
    if atype == &#39;int16&#39;:
        return 2
    raise ValueError(&#39;Supported atypes are either int8 or int16&#39;)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.convert_audio_to_db"><code class="name flex">
<span>def <span class="ident">convert_audio_to_db</span></span>(<span>audio, rate, frame_duration, ref_func=&lt;function &lt;lambda&gt;&gt;, min_threshold=1e-10, db_threshold=80.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the audio to decibels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame</dd>
<dt><strong><code>ref_func</code></strong></dt>
<dd>A function, which takes a magnitude and returns a value</dd>
<dt><strong><code>min_threshold</code></strong></dt>
<dd>A float, which is the minimum magnitude</dd>
<dt><strong><code>db_threshold</code></strong></dt>
<dd>A float, which is the threshold for the audio
in decibels</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of a numpy ndarray, which has 1 dimension,
and an integer (new rate)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_audio_to_db(audio, rate, frame_duration, ref_func=lambda x: 1,
                        min_threshold=1e-10, db_threshold=80.0):
    &#34;&#34;&#34;Converts the audio to decibels.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
        ref_func: A function, which takes a magnitude and returns a value
        min_threshold: A float, which is the minimum magnitude
        db_threshold: A float, which is the threshold for the audio
                      in decibels

    Returns:
        A tuple of a numpy ndarray, which has 1 dimension,
            and an integer (new rate)
    &#34;&#34;&#34;
    mag, new_rate = for_each_frame(audio, rate, frame_duration,
                                   lambda sample: calc_rms(sample))
    y = 10.0 * np.log10(np.maximum(min_threshold, mag))
    y -= 10.0 * np.log10(np.maximum(min_threshold, ref_func(mag)))
    y = y if db_threshold is None else np.maximum(y, y.max() - db_threshold)
    return y, new_rate</code></pre>
</details>
</dd>
<dt id="paiutils.audio.convert_power_to_db"><code class="name flex">
<span>def <span class="ident">convert_power_to_db</span></span>(<span>power, ref_func=&lt;function &lt;lambda&gt;&gt;, min_threshold=1e-10, db_threshold=80.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts power to decibels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>power</code></strong></dt>
<dd>A numpy ndarray, which has 1 or 2 dimensions</dd>
<dt><strong><code>min_threshold</code></strong></dt>
<dd>A float, which is the minimum magnitude</dd>
<dt><strong><code>db_threshold</code></strong></dt>
<dd>A float, which is the threshold for the audio
in decibels</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 or 2 dimensions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_power_to_db(power, ref_func=lambda x: 1,
                        min_threshold=1e-10, db_threshold=80.0):
    &#34;&#34;&#34;Converts power to decibels.

    Args:
        power: A numpy ndarray, which has 1 or 2 dimensions
        min_threshold: A float, which is the minimum magnitude
        db_threshold: A float, which is the threshold for the audio
                in decibels

    Returns:
        A numpy ndarray, which has 1 or 2 dimensions
    &#34;&#34;&#34;
    mag = np.abs(power)
    y = 10.0 * np.log10(np.maximum(min_threshold, mag))
    y -= 10.0 * np.log10(np.maximum(min_threshold, ref_func(mag)))
    y = y if db_threshold is None else np.maximum(y, y.max() - db_threshold)
    return y</code></pre>
</details>
</dd>
<dt id="paiutils.audio.convert_spectrogram_to_audio"><code class="name flex">
<span>def <span class="ident">convert_spectrogram_to_audio</span></span>(<span>spectrogram, rate, real=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts a nonoverlapping spectrogram back to audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>spectrogram</code></strong></dt>
<dd>A numpy ndarray, which has 2 dimensions</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which each frame is taken</dd>
<dt><strong><code>real</code></strong></dt>
<dd>A boolean, which determines if one side hermitian ffts
should be used or real ffts</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of a numpy ndarray, which has 1 dimension,
and an integer (new rate)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_spectrogram_to_audio(spectrogram, rate, real=True):
    &#34;&#34;&#34;Converts a nonoverlapping spectrogram back to audio.

    Args:
        spectrogram: A numpy ndarray, which has 2 dimensions
        rate: An integer, which is the rate at which each frame is taken
        real: A boolean, which determines if one side hermitian ffts
              should be used or real ffts

    Returns:
        A tuple of a numpy ndarray, which has 1 dimension,
            and an integer (new rate)
    &#34;&#34;&#34;
    if real:
        def ft(frame):
            frame2 = np.hstack([frame, np.flip(frame[1:-1])])
            return np.real(np.fft.ihfft(frame2))
    else:
        def ft(frame):
            return np.fft.irfft(frame)
    frames = []
    for frame in spectrogram:
        frames.append(ft(frame))
    return np.hstack(frames), len(frames[0]) * rate</code></pre>
</details>
</dd>
<dt id="paiutils.audio.convert_width_to_atype"><code class="name flex">
<span>def <span class="ident">convert_width_to_atype</span></span>(<span>width)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts a number of bytes to an audio type.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>width</code></strong></dt>
<dd>An integer, which is the number of bytes wide</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A string, which is the audio type</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_width_to_atype(width):
    &#34;&#34;&#34;Converts a number of bytes to an audio type.

    Args:
        width: An integer, which is the number of bytes wide
    
    Returns:
        A string, which is the audio type
    &#34;&#34;&#34;
    if width == 1:
        atype = &#39;int8&#39;
    elif width == 2:
        atype = &#39;int16&#39;
    else:
        raise ValueError(&#39;Supported widths are either 1 or 2&#39;)
    return atype</code></pre>
</details>
</dd>
<dt id="paiutils.audio.file_play"><code class="name flex">
<span>def <span class="ident">file_play</span></span>(<span>filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Plays the audio file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>A string, which is the directory or filename of the
file to load</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def file_play(filename):
    &#34;&#34;&#34;Plays the audio file.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
    &#34;&#34;&#34;
    cmd = [SOX_PATH, f&#39;&#34;{filename}&#34;&#39;, &#39;-t waveaudio&#39;]
    subprocess.run(&#39; &#39;.join(cmd), stdout=subprocess.DEVNULL,
                   stderr=subprocess.DEVNULL)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.file_record"><code class="name flex">
<span>def <span class="ident">file_record</span></span>(<span>filename, seconds, rate, atype=None, recording_device_name='Microphone')</span>
</code></dt>
<dd>
<div class="desc"><p>Records audio from the recording device to a file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>A string, which is the directory or filename of the
file to load</dd>
<dt><strong><code>seconds</code></strong></dt>
<dd>A float, which is the length of the recording</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>atype</code></strong></dt>
<dd>A string, which is the audio type (default: int16)</dd>
<dt><strong><code>recording_device_name</code></strong></dt>
<dd>A string, which is the name of the
recording device</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def file_record(filename, seconds, rate, atype=None,
                recording_device_name=&#39;Microphone&#39;):
    &#34;&#34;&#34;Records audio from the recording device to a file.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
        seconds: A float, which is the length of the recording
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
        recording_device_name: A string, which is the name of the
                               recording device
    &#34;&#34;&#34;
    if atype is None:
        atype = &#39;int16&#39;
    cmd = [SOX_PATH, f&#39;-b {convert_atype_to_width(atype) * 8}&#39;,
           &#39;-c 1&#39;, f&#39;-r {rate}&#39;, f&#39;-t waveaudio {recording_device_name}&#39;,
           &#39;-e signed-integer&#39;]
    cmd += [f&#39;&#34;{filename}&#34;&#39;]
    cmd += [f&#39;trim 0 {seconds}&#39;]
    subprocess.run(&#39; &#39;.join(cmd), stdout=subprocess.DEVNULL,
                   stderr=subprocess.DEVNULL)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.find_gaps"><code class="name flex">
<span>def <span class="ident">find_gaps</span></span>(<span>audio, rate, frame_duration, ambient_power=0.0001)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the length of gaps in the audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame
to check</dd>
<dt><strong><code>ambient_power</code></strong></dt>
<dd>A float, which is the Root Mean Square of ambient noise</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of tuples with the first value in the tuple being the start
of a gap and the second value the end</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_gaps(audio, rate, frame_duration, ambient_power=1e-4):
    &#34;&#34;&#34;Finds the length of gaps in the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise

    Returns:
        A list of tuples with the first value in the tuple being the start
            of a gap and the second value the end
    &#34;&#34;&#34;
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    gaps = []
    start = None
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power:
            if start is not None:
                end = (ndx + 1) * frame_length
                gaps.append((start, end))
            start = None
        elif start is None:
            start = ndx * frame_length
    if start is not None:
        gaps.append((start, len(audio)))
    return gaps</code></pre>
</details>
</dd>
<dt id="paiutils.audio.for_each_frame"><code class="name flex">
<span>def <span class="ident">for_each_frame</span></span>(<span>audio, rate, frame_duration, func)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls a function on each frame.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame</dd>
<dt><strong><code>func</code></strong></dt>
<dd>A function, which takes a frame and returns a value</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of a numpy ndarray of results from func and integer
(new rate)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def for_each_frame(audio, rate, frame_duration, func):
    &#34;&#34;&#34;Calls a function on each frame.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
        func: A function, which takes a frame and returns a value

    Returns:
        A tuple of a numpy ndarray of results from func and integer
            (new rate)
    &#34;&#34;&#34;
    frames = np.array_split(
        audio, int(audio.size / (rate * frame_duration))
    )
    audio = np.array([func(frame) for frame in frames])
    return audio, round(1 / frame_duration)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>filename, rate=None, assert_mono=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Changes the audio's sample rate.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>A string, which is the directory or filename of the
file to load</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>assert_mono</code></strong></dt>
<dd>A boolean, which determines if an assertion error
should be raise if there are more than one channel
in the audio or if it should be converted to one
channel</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of the loaded audio, rate, and atype</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(filename, rate=None, assert_mono=True):
    &#34;&#34;&#34;Changes the audio&#39;s sample rate.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
        rate: An integer, which is the rate at which samples are taken
        assert_mono: A boolean, which determines if an assertion error
                     should be raise if there are more than one channel
                     in the audio or if it should be converted to one
                     channel

    Returns:
        A tuple of the loaded audio, rate, and atype
    &#34;&#34;&#34;
    if filename.split(&#39;.&#39;)[-1] == &#39;wav&#39;:
        file = wave.open(filename, &#39;r&#39;)
        assert file.getnchannels() == 1 or not assert_mono, (
            &#39;Can only load mono-channel files&#39;
        )
    if (filename.split(&#39;.&#39;)[-1] == &#39;wav&#39;
            and file.getnchannels() == 1
            and (rate is None or file.getframerate() == rate)):
        atype = convert_width_to_atype(file.getsampwidth())
        rate = file.getframerate()
        audio = file.readframes(file.getnframes())
        audio = np.frombuffer(audio, dtype=atype) / np.iinfo(atype).max
        file.close()
    else:
        if filename.split(&#39;.&#39;)[-1] == &#39;wav&#39;:
            file.close()
        temp_filename = os.path.join(
            util_dir, str(np.random.randint(10000, 100000))+&#39;.wav&#39;
        )
        if rate is None:
            cmd = [SOX_PATH, filename, &#39;-c 1&#39;, temp_filename]
        else:
            cmd = [SOX_PATH, filename, &#39;-r &#39; + str(rate), &#39;-c 1&#39;,
                   temp_filename]
        subprocess.run(cmd, stdout=subprocess.DEVNULL,
                       stderr=subprocess.DEVNULL)
        try:
            with wave.open(temp_filename, &#39;r&#39;) as file:
                atype = convert_width_to_atype(file.getsampwidth())
                rate = file.getframerate()
                audio = file.readframes(file.getnframes())
                audio = np.frombuffer(audio, dtype=atype) / np.iinfo(atype).max
        finally:
            os.remove(temp_filename)
    return audio, rate, atype</code></pre>
</details>
</dd>
<dt id="paiutils.audio.play"><code class="name flex">
<span>def <span class="ident">play</span></span>(<span>audio, rate, atype=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plays the audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>atype</code></strong></dt>
<dd>A string, which is the audio type (default: int16)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def play(audio, rate, atype=None):
    &#34;&#34;&#34;Plays the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
    &#34;&#34;&#34;
    global CHUNK, USE_PYAUDIO
    if atype is None:
        atype = &#39;int16&#39;
    if USE_PYAUDIO:
        p = pyaudio.PyAudio()

        if atype == &#39;int16&#39;:
            patype = pyaudio.paInt16
        elif atype == &#39;int8&#39;:
            patype = pyaudio.paInt8
        else:
            raise ValueError(&#39;Supported atypes are either int8 or int16&#39;)
        stream = p.open(format=patype,
                        channels=1,
                        rate=rate,
                        output=True)

        audio = (audio * np.iinfo(atype).max).astype(atype)
        data = np.array_split(audio, CHUNK)
        for frame in data:
            stream.write(frame.tobytes())

        stream.stop_stream()
        stream.close()
        p.terminate()
    else:
        temp_filename = os.path.join(
            util_dir, str(np.random.randint(10000, 100000)) + &#39;.wav&#39;
        )
        audio = np.pad(audio, (0, rate), &#39;constant&#39;)
        save(temp_filename, audio, rate, atype=atype)
        try:
            file_play(temp_filename)
        finally:
            os.remove(temp_filename)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>audio, seconds=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Plots the audio on a graph.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>seconds</code></strong></dt>
<dd>A float, which is the number of seconds to show the plot</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(audio, seconds=0):
    &#34;&#34;&#34;Plots the audio on a graph.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        seconds: A float, which is the number of seconds to show the plot
    &#34;&#34;&#34;
    plt.plot(audio)
    if seconds == 0:
        plt.show()
    else:
        plt.show(block=False)
        plt.pause(seconds)
        plt.close()</code></pre>
</details>
</dd>
<dt id="paiutils.audio.record"><code class="name flex">
<span>def <span class="ident">record</span></span>(<span>seconds, rate, atype=None, recording_device_name='Microphone')</span>
</code></dt>
<dd>
<div class="desc"><p>Records audio from the recording device.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>seconds</code></strong></dt>
<dd>A float, which is the length of the recording</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>atype</code></strong></dt>
<dd>A string, which is the audio type (default: int16)</dd>
<dt><strong><code>recording_device_name</code></strong></dt>
<dd>A string, which is the name of the
recording device</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple of the loaded audio, rate, and atype</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def record(seconds, rate, atype=None, recording_device_name=&#39;Microphone&#39;):
    &#34;&#34;&#34;Records audio from the recording device.

    Args:
        seconds: A float, which is the length of the recording
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
        recording_device_name: A string, which is the name of the
                               recording device

    Returns:
        A tuple of the loaded audio, rate, and atype
    &#34;&#34;&#34;
    global CHUNK, USE_PYAUDIO
    if atype is None:
        atype = &#39;int16&#39;
    if USE_PYAUDIO:
        p = pyaudio.PyAudio()

        if atype == &#39;int16&#39;:
            patype = pyaudio.paInt16
        elif atype == &#39;int8&#39;:
            patype = pyaudio.paInt8
        else:
            raise ValueError(&#39;Supported atypes are either int8 or int16&#39;)
        stream = p.open(format=patype,
                        channels=1,
                        rate=rate,
                        input=True,
                        frames_per_buffer=CHUNK)

        frames = []
        for i in range(0, int(rate / CHUNK * seconds)):
            frames.append(stream.read(CHUNK))

        stream.stop_stream()
        stream.close()
        p.terminate()
        audio = (np.frombuffer(b&#39;&#39;.join(frames), dtype=atype) /
                 np.iinfo(atype).max)
    else:
        temp_filename = os.path.join(
            util_dir, str(np.random.randint(10000, 100000))+&#39;.wav&#39;
        )
        file_record(temp_filename, seconds, rate, atype=atype,
                    recording_device_name=recording_device_name)
        try:
            with wave.open(temp_filename, &#39;r&#39;) as file:
                atype = convert_width_to_atype(file.getsampwidth())
                rate = file.getframerate()
                audio = file.readframes(file.getnframes())
                audio = np.frombuffer(audio, dtype=atype) / np.iinfo(atype).max
        finally:
            os.remove(temp_filename)
    return audio, rate, atype</code></pre>
</details>
</dd>
<dt id="paiutils.audio.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>filename, audio, rate, atype=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves the audio to a file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>A string, which is the directory or filename of the
file to load</dd>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>atype</code></strong></dt>
<dd>A string, which is the audio type (default: int16)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(filename, audio, rate, atype=None):
    &#34;&#34;&#34;Saves the audio to a file.

    Args:
        filename: A string, which is the directory or filename of the
                  file to load
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        atype: A string, which is the audio type (default: int16)
    &#34;&#34;&#34;
    if atype is None:
        atype = &#39;int16&#39;
    with wave.open(filename, &#39;wb&#39;) as file:
        file.setframerate(rate)
        file.setnchannels(1)
        file.setsampwidth(convert_atype_to_width(atype))
        audio = (audio * np.iinfo(atype).max).astype(atype)
        file.writeframes(audio.tobytes())</code></pre>
</details>
</dd>
<dt id="paiutils.audio.set_duration"><code class="name flex">
<span>def <span class="ident">set_duration</span></span>(<span>audio, rate, seconds, mode='R', pad_value=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the duration of audio in seconds.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>seconds</code></strong></dt>
<dd>A float, which is the duration to set the audio to</dd>
<dt><strong><code>mode</code></strong></dt>
<dd>A string ('L','R','B'), which determines where to pad or remove</dd>
<dt><strong><code>pad_values</code></strong></dt>
<dd>A float within -1.0 to 1.0 (inclusive), which will be
the value if the audio is padded</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_duration(audio, rate, seconds, mode=&#39;R&#39;, pad_value=0):
    &#34;&#34;&#34;Sets the duration of audio in seconds.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        seconds: A float, which is the duration to set the audio to
        mode: A string (&#39;L&#39;,&#39;R&#39;,&#39;B&#39;), which determines where to pad or remove
        pad_values: A float within -1.0 to 1.0 (inclusive), which will be
                    the value if the audio is padded

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    return set_length(audio, round(rate * seconds), mode, pad_value)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.set_length"><code class="name flex">
<span>def <span class="ident">set_length</span></span>(<span>audio, length, mode='R', pad_value=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the length of audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>length</code></strong></dt>
<dd>An integer, which is the length to set the audio to</dd>
<dt><strong><code>mode</code></strong></dt>
<dd>A string ('L','R','B'), which determines where to pad or remove</dd>
<dt><strong><code>pad_values</code></strong></dt>
<dd>A float within -1.0 to 1.0 (inclusive), which will be
the if the audio is padded</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_length(audio, length, mode=&#39;R&#39;, pad_value=0):
    &#34;&#34;&#34;Sets the length of audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        length: An integer, which is the length to set the audio to
        mode: A string (&#39;L&#39;,&#39;R&#39;,&#39;B&#39;), which determines where to pad or remove
        pad_values: A float within -1.0 to 1.0 (inclusive), which will be
                    the if the audio is padded

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    mode = mode.lower()
    assert mode in &#39;lbr&#39;, &#39;mode must be L(Left), R(Right), or B(Both)&#39;
    size = audio.size
    if size &gt; length:
        if mode == &#39;l&#39;:
            return audio[size-length:]
        elif mode == &#39;r&#39;:
            return audio[:length-size]
        else:
            return audio[(size-length)//2:-(size-length)//2]
    else:
        if mode == &#39;l&#39;:
            return np.pad(audio, (length-size, 0),
                          &#39;constant&#39;, constant_values=pad_value)
        elif mode == &#39;r&#39;:
            return np.pad(audio, (0, length-size),
                          &#39;constant&#39;, constant_values=pad_value)
        else:
            return np.pad(audio, ((length-size)//2, (length-size+1)//2),
                          &#39;constant&#39;, constant_values=pad_value)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.set_power"><code class="name flex">
<span>def <span class="ident">set_power</span></span>(<span>audio, power)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the power of the audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>power</code></strong></dt>
<dd>A float, which is the Root Mean Square to set the audio to</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_power(audio, power):
    &#34;&#34;&#34;Sets the power of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        power: A float, which is the Root Mean Square to set the audio to

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    return np.clip(power / calc_rms(audio) * audio, -1, 1)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.set_speed"><code class="name flex">
<span>def <span class="ident">set_speed</span></span>(<span>audio, rate, seconds)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets the speed of the audio and keeps the RMS power the same.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>seconds</code></strong></dt>
<dd>A float, which is the number of seconds the audio
should be set to</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_speed(audio, rate, seconds):
    &#34;&#34;&#34;Sets the speed of the audio and keeps the RMS power the same.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        seconds: A float, which is the number of seconds the audio
                 should be set to

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    power = calc_rms(audio)
    y = np.fft.rfft(audio)
    ns = round(seconds * rate)
    return set_power(np.fft.irfft(y, ns), power)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.shift_pitch"><code class="name flex">
<span>def <span class="ident">shift_pitch</span></span>(<span>audio, rate, steps)</span>
</code></dt>
<dd>
<div class="desc"><p>Shifts the pitch of the audio.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shift_pitch(audio, rate, steps):
    &#34;&#34;&#34;Shifts the pitch of the audio.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken

    Returns:
        A numpy ndarray, which has 1 dimension
    &#34;&#34;&#34;
    y = np.fft.rfft(audio)
    y = np.roll(y, steps)
    if steps &gt; 0:
        y[:steps] = 0
    else:
        y[steps:] = 0
    return np.fft.irfft(y, audio.size)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.split"><code class="name flex">
<span>def <span class="ident">split</span></span>(<span>audio, rate, frame_duration, ambient_power=0.0001, min_gap=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Splits the audio into audio segments on ambient frames.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame
to check</dd>
<dt><strong><code>ambient_power</code></strong></dt>
<dd>A float, which is the Root Mean Square of ambient noise</dd>
<dt><strong><code>min_gap</code></strong></dt>
<dd>An integer, which is the number of frames to consider until
ambient frames are removed</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of numpy ndarray, which are 1 dimension each and have
values within -1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split(audio, rate, frame_duration, ambient_power=1e-4, min_gap=None):
    &#34;&#34;&#34;Splits the audio into audio segments on ambient frames.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise
        min_gap: An integer, which is the number of frames to consider until
                 ambient frames are removed

    Returns:
        A list of numpy ndarray, which are 1 dimension each and have
            values within -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    if min_gap is None:
        min_gap = frame_duration
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    audios = []
    last_split = 0
    gap = 0
    on = False
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power:
            gap = 0
            on = True
        else:
            gap += frame_duration
            if gap &gt;= min_gap and on:
                gap = 0
                on = False
                next_split = (ndx + 1) * frame_length
                audios.append(audio[last_split:next_split])
                last_split = next_split
    return audios</code></pre>
</details>
</dd>
<dt id="paiutils.audio.trim_all"><code class="name flex">
<span>def <span class="ident">trim_all</span></span>(<span>audio, rate, frame_duration, ambient_power=0.0001)</span>
</code></dt>
<dd>
<div class="desc"><p>Trims ambient silence in the audio anywhere.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame
to check</dd>
<dt><strong><code>ambient_power</code></strong></dt>
<dd>A float, which is the Root Mean Square of ambient noise</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_all(audio, rate, frame_duration, ambient_power=1e-4):
    &#34;&#34;&#34;Trims ambient silence in the audio anywhere.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    new_audio = []
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power:
            new_audio += audio[ndx*frame_length:(ndx+1)*frame_length].tolist()
    return np.array(new_audio)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.trim_sides"><code class="name flex">
<span>def <span class="ident">trim_sides</span></span>(<span>audio, rate, frame_duration, ambient_power=0.0001)</span>
</code></dt>
<dd>
<div class="desc"><p>Trims ambient silence in the audio only on the sides.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame
to check</dd>
<dt><strong><code>ambient_power</code></strong></dt>
<dd>A float, which is the Root Mean Square of ambient noise</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_sides(audio, rate, frame_duration, ambient_power=1e-4):
    &#34;&#34;&#34;Trims ambient silence in the audio only on the sides.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check
        ambient_power: A float, which is the Root Mean Square of ambient noise

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    powers, fr = for_each_frame(audio, rate, frame_duration, calc_rms)
    frame_length = round(rate / fr)
    start_ndx = None
    end_ndx = None
    for ndx, power in enumerate(powers):
        if power &gt; ambient_power and start_ndx is None:
            start_ndx = ndx * frame_length
            break
    else:
        start_ndx = 0
    for ndx, power in enumerate(reversed(powers)):
        if power &gt; ambient_power and end_ndx is None:
            end_ndx = (len(powers) - ndx) * frame_length
            break
    else:
        end_ndx = len(audio)
    if start_ndx &lt; end_ndx:
        return audio[start_ndx:end_ndx]
    return audio</code></pre>
</details>
</dd>
<dt id="paiutils.audio.vad_split"><code class="name flex">
<span>def <span class="ident">vad_split</span></span>(<span>audio, rate, frame_duration, aggressiveness=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Splits the audio into audio segments on non-speech frames.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer, which is the rate at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float, which is the duration of each frame
to check</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of numpy ndarray, which are 1 dimension each and
have values within -1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vad_split(audio, rate, frame_duration, aggressiveness=1):
    &#34;&#34;&#34;Splits the audio into audio segments on non-speech frames.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer, which is the rate at which samples are taken
        frame_duration: A float, which is the duration of each frame
                        to check

    Returns:
        A list of numpy ndarray, which are 1 dimension each and
            have values within -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    assert rate in (8000, 16000, 32000, 48000), (
        &#39;Invalid Rate, use 8000, 16000, 32000, or 48000&#39;
    )
    assert frame_duration in (.01, .02, .03), (
        &#39;Invalid frame_dur, use .01, .02, .03&#39;
    )
    assert 0 &lt;= aggressiveness &lt;= 3, (
        &#39;Invalid aggressiveness, must be between 0 and 3&#39;
    )

    audio = (audio * np.iinfo(&#39;int16&#39;).max).astype(&#39;int16&#39;)

    vad = webrtcvad.Vad(aggressiveness)
    frame_size = int(rate * frame_duration)
    offset = 0
    off = True
    voiced_frames = []
    while offset + frame_size &lt; len(audio):
        frame = audio[offset:offset + frame_size]
        if vad.is_speech(frame.tobytes(), rate):
            if off is True:
                off = False
                voiced_frames.append([frame])
            else:
                voiced_frames[-1].append(frame)
        else:
            off = True
        offset += frame_size
    if len(voiced_frames) == 0:
        return np.array([audio])
    for ndx in range(len(voiced_frames)):
        voiced_frames[ndx] = np.hstack(voiced_frames[ndx])
    return voiced_frames</code></pre>
</details>
</dd>
<dt id="paiutils.audio.vad_trim_all"><code class="name flex">
<span>def <span class="ident">vad_trim_all</span></span>(<span>audio, rate, frame_duration, aggressiveness=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Trims anywhere in the audio that does not contain speech.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer (8000, 16000, 32000, 48000), which is the rate
at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float (.01, .02, .03), which is the duration
of each frame to check</dd>
<dt><strong><code>aggressiveness</code></strong></dt>
<dd>A integer (0, 1, 2, 3), which is the level of
aggressiveness to trim non-speech</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vad_trim_all(audio, rate, frame_duration, aggressiveness=1):
    &#34;&#34;&#34;Trims anywhere in the audio that does not contain speech.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer (8000, 16000, 32000, 48000), which is the rate
              at which samples are taken
        frame_duration: A float (.01, .02, .03), which is the duration
                        of each frame to check
        aggressiveness: A integer (0, 1, 2, 3), which is the level of
                        aggressiveness to trim non-speech

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    assert rate in (8000, 16000, 32000, 48000), (
        &#39;Invalid Rate, use 8000, 16000, 32000, or 48000&#39;
    )
    assert frame_duration in (.01, .02, .03), (
        &#39;Invalid frame_dur, use .01, .02, .03&#39;
    )
    assert 0 &lt;= aggressiveness &lt;= 3, (
        &#39;Invalid aggressiveness, must be between 0 and 3&#39;
    )

    audio = (audio * np.iinfo(&#39;int16&#39;).max).astype(&#39;int16&#39;)

    vad = webrtcvad.Vad(aggressiveness)
    frame_size = int(rate * frame_duration)
    offset = 0
    voiced_frames = []
    while offset + frame_size &lt; len(audio):
        frame = audio[offset:offset + frame_size]
        if vad.is_speech(frame.tobytes(), rate):
            voiced_frames.append(frame)
        offset += frame_size
    if len(voiced_frames) == 0:
        return audio
    return np.hstack(voiced_frames)</code></pre>
</details>
</dd>
<dt id="paiutils.audio.vad_trim_sides"><code class="name flex">
<span>def <span class="ident">vad_trim_sides</span></span>(<span>audio, rate, frame_duration, aggressiveness=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Trims the sides in the audio that do not contain speech.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>audio</code></strong></dt>
<dd>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</dd>
<dt><strong><code>rate</code></strong></dt>
<dd>An integer (8000, 16000, 32000, 48000), which is the rate
at which samples are taken</dd>
<dt><strong><code>frame_duration</code></strong></dt>
<dd>A float (.01, .02, .03), which is the duration
of each frame to check</dd>
<dt><strong><code>aggressiveness</code></strong></dt>
<dd>A integer (0, 1, 2, 3), which is the level of
aggressiveness to trim non-speech</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A numpy ndarray, which has 1 dimension and values within
-1.0 to 1.0 (inclusive)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vad_trim_sides(audio, rate, frame_duration, aggressiveness=1):
    &#34;&#34;&#34;Trims the sides in the audio that do not contain speech.

    Args:
        audio: A numpy ndarray, which has 1 dimension and values within
               -1.0 to 1.0 (inclusive)
        rate: An integer (8000, 16000, 32000, 48000), which is the rate
              at which samples are taken
        frame_duration: A float (.01, .02, .03), which is the duration
                        of each frame to check
        aggressiveness: A integer (0, 1, 2, 3), which is the level of
                        aggressiveness to trim non-speech

    Returns:
        A numpy ndarray, which has 1 dimension and values within
            -1.0 to 1.0 (inclusive)
    &#34;&#34;&#34;
    assert rate in (8000, 16000, 32000, 48000), (
        &#39;Invalid Rate, use 8000, 16000, 32000, or 48000&#39;
    )
    assert frame_duration in (.01, .02, .03), (
        &#39;Invalid frame_dur, use .01, .02, .03&#39;
    )
    assert 0 &lt;= aggressiveness &lt;= 3, (
        &#39;Invalid aggressiveness, must be between 0 and 3&#39;
    )

    audio = (audio * np.iinfo(&#39;int16&#39;).max).astype(&#39;int16&#39;)

    vad = webrtcvad.Vad(aggressiveness)
    frame_size = int(rate * frame_duration)
    offset = 0
    start_ndx = 0
    while offset + frame_size &lt; len(audio):
        frame = audio[offset:offset + frame_size]
        if vad.is_speech(frame.tobytes(), rate):
            start_ndx = offset
            break
        offset += frame_size
    else:
        return audio
    offset = len(audio)
    end_ndx = len(audio)
    while offset - frame_size &gt; start_ndx:
        frame = audio[offset - frame_size:offset]
        if vad.is_speech(frame.tobytes(), rate):
            end_ndx = offset
            break
        offset -= frame_size
    return audio[start_ndx:end_ndx]</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="paiutils" href="index.html">paiutils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="paiutils.audio.adjust_speed" href="#paiutils.audio.adjust_speed">adjust_speed</a></code></li>
<li><code><a title="paiutils.audio.adjust_volume" href="#paiutils.audio.adjust_volume">adjust_volume</a></code></li>
<li><code><a title="paiutils.audio.blend" href="#paiutils.audio.blend">blend</a></code></li>
<li><code><a title="paiutils.audio.calc_duration" href="#paiutils.audio.calc_duration">calc_duration</a></code></li>
<li><code><a title="paiutils.audio.calc_rms" href="#paiutils.audio.calc_rms">calc_rms</a></code></li>
<li><code><a title="paiutils.audio.change_rate" href="#paiutils.audio.change_rate">change_rate</a></code></li>
<li><code><a title="paiutils.audio.compute_fbank" href="#paiutils.audio.compute_fbank">compute_fbank</a></code></li>
<li><code><a title="paiutils.audio.compute_mfcc" href="#paiutils.audio.compute_mfcc">compute_mfcc</a></code></li>
<li><code><a title="paiutils.audio.compute_spectrogram" href="#paiutils.audio.compute_spectrogram">compute_spectrogram</a></code></li>
<li><code><a title="paiutils.audio.convert_amplitude_to_db" href="#paiutils.audio.convert_amplitude_to_db">convert_amplitude_to_db</a></code></li>
<li><code><a title="paiutils.audio.convert_atype_to_width" href="#paiutils.audio.convert_atype_to_width">convert_atype_to_width</a></code></li>
<li><code><a title="paiutils.audio.convert_audio_to_db" href="#paiutils.audio.convert_audio_to_db">convert_audio_to_db</a></code></li>
<li><code><a title="paiutils.audio.convert_power_to_db" href="#paiutils.audio.convert_power_to_db">convert_power_to_db</a></code></li>
<li><code><a title="paiutils.audio.convert_spectrogram_to_audio" href="#paiutils.audio.convert_spectrogram_to_audio">convert_spectrogram_to_audio</a></code></li>
<li><code><a title="paiutils.audio.convert_width_to_atype" href="#paiutils.audio.convert_width_to_atype">convert_width_to_atype</a></code></li>
<li><code><a title="paiutils.audio.file_play" href="#paiutils.audio.file_play">file_play</a></code></li>
<li><code><a title="paiutils.audio.file_record" href="#paiutils.audio.file_record">file_record</a></code></li>
<li><code><a title="paiutils.audio.find_gaps" href="#paiutils.audio.find_gaps">find_gaps</a></code></li>
<li><code><a title="paiutils.audio.for_each_frame" href="#paiutils.audio.for_each_frame">for_each_frame</a></code></li>
<li><code><a title="paiutils.audio.load" href="#paiutils.audio.load">load</a></code></li>
<li><code><a title="paiutils.audio.play" href="#paiutils.audio.play">play</a></code></li>
<li><code><a title="paiutils.audio.plot" href="#paiutils.audio.plot">plot</a></code></li>
<li><code><a title="paiutils.audio.record" href="#paiutils.audio.record">record</a></code></li>
<li><code><a title="paiutils.audio.save" href="#paiutils.audio.save">save</a></code></li>
<li><code><a title="paiutils.audio.set_duration" href="#paiutils.audio.set_duration">set_duration</a></code></li>
<li><code><a title="paiutils.audio.set_length" href="#paiutils.audio.set_length">set_length</a></code></li>
<li><code><a title="paiutils.audio.set_power" href="#paiutils.audio.set_power">set_power</a></code></li>
<li><code><a title="paiutils.audio.set_speed" href="#paiutils.audio.set_speed">set_speed</a></code></li>
<li><code><a title="paiutils.audio.shift_pitch" href="#paiutils.audio.shift_pitch">shift_pitch</a></code></li>
<li><code><a title="paiutils.audio.split" href="#paiutils.audio.split">split</a></code></li>
<li><code><a title="paiutils.audio.trim_all" href="#paiutils.audio.trim_all">trim_all</a></code></li>
<li><code><a title="paiutils.audio.trim_sides" href="#paiutils.audio.trim_sides">trim_sides</a></code></li>
<li><code><a title="paiutils.audio.vad_split" href="#paiutils.audio.vad_split">vad_split</a></code></li>
<li><code><a title="paiutils.audio.vad_trim_all" href="#paiutils.audio.vad_trim_all">vad_trim_all</a></code></li>
<li><code><a title="paiutils.audio.vad_trim_sides" href="#paiutils.audio.vad_trim_sides">vad_trim_sides</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>